{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Constants\n",
        "EVENT_BUS_NAME = \"\"\n",
        "EVENT_EMITTER_FUNCTION = \"\"\n",
        "SEND_EVENTS_TO_SAGEMAKER_FUNCTION = \"\"\n",
        "STATE_MACHINE_ARN = \"\"\n",
        "WAIT_TIME = 10\n",
        "DYNAMODB_TABLE = ''\n",
        "PRIMARY_SQS_QUEUE_URL = ''\n",
        "DLQ_NAME = ''\n",
        "\n",
        "MAX_RETRIES = 5\n",
        "\n",
        "# Mapping of event names to sources\n",
        "EVENT_SOURCES = {\n",
        "    \"myapp.ec2\": [\n",
        "        \"RunInstances\",\n",
        "        \"TerminateInstances\",\n",
        "        \"DescribeInstances\",\n",
        "        \"CreateSecurityGroup\",\n",
        "        \"DeleteSecurityGroup\",\n",
        "        \"AuthorizeSecurityGroupIngress\",\n",
        "        \"RevokeSecurityGroupIngress\",\n",
        "        \"RevokeSecurityGroupEgress\",\n",
        "        \"DescribeInstanceTypes\",\n",
        "        \"DescribeImages\",\n",
        "        \"DescribeSnapshots\",\n",
        "        \"DescribeVpcs\",\n",
        "        \"DescribeSubnets\",\n",
        "        \"DescribeSecurityGroups\",\n",
        "        \"DescribeAddresses\",\n",
        "        \"DescribeAvailabilityZones\",\n",
        "        \"DescribeLaunchTemplates\",\n",
        "        \"DescribePlacementGroups\",\n",
        "        \"AutomatedDefaultVpcCreation\",\n",
        "        \"DescribeRegions\",\n",
        "    ],\n",
        "    \"myapp.cloudtrail\": [\n",
        "        \"LookupEvents\",\n",
        "        \"GetEventSelectors\",\n",
        "        \"ListTags\",\n",
        "        \"GetInsightSelectors\",\n",
        "        \"GetTrailStatus\",\n",
        "        \"DescribeTrails\",\n",
        "        \"ListTrails\",\n",
        "        \"StartLogging\",\n",
        "        \"CreateTrail\",\n",
        "        \"PutEventSelectors\",\n",
        "        \"ListEventDataStores\",\n",
        "        \"GetEbsEncryptionByDefault\",\n",
        "    ],\n",
        "    \"myapp.cloudshell\": [\n",
        "        \"CreateSession\",\n",
        "        \"DeleteSession\",\n",
        "        \"RedeemCode\",\n",
        "        \"PutCredentials\",\n",
        "        \"GetEnvironmentStatus\",\n",
        "        \"SendHeartBeat\",\n",
        "        \"DescribeEnvironments\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "EVENT_NAME_TO_SOURCE = {}\n",
        "for source, events in EVENT_SOURCES.items():\n",
        "    for event in events:\n",
        "        EVENT_NAME_TO_SOURCE[event] = source\n",
        "\n",
        "=def log_to_dynamodb(\n",
        "    execution_id,\n",
        "    step,\n",
        "    status_code,\n",
        "    message,\n",
        "    predicted_source=None,\n",
        "    score=None,\n",
        "    response=None,\n",
        "    step_function_status=None,\n",
        "    step_function_output=None,\n",
        "    lambda_output=None\n",
        "):\n",
        "    try:\n",
        "        item = {\n",
        "            'execution_id': {'S': execution_id},\n",
        "            'step': {'S': step},\n",
        "            'statusCode': {'S': str(status_code)},\n",
        "            'message': {'S': message},\n",
        "            'timestamp': {'S': datetime.utcnow().isoformat()}\n",
        "        }\n",
        "        if predicted_source:\n",
        "            item['predicted_source'] = {'S': predicted_source}\n",
        "        if score is not None:\n",
        "            item['score'] = {'N': str(score)}\n",
        "        if response:\n",
        "            try:\n",
        "                serialized_response = json.dumps(response)\n",
        "                item['response'] = {'S': serialized_response}\n",
        "            except (TypeError, ValueError):\n",
        "                item['response'] = {'S': str(response)}\n",
        "        if step_function_status:\n",
        "            item['step_function_status'] = {'S': step_function_status}\n",
        "        if step_function_output:\n",
        "            try:\n",
        "                serialized_output = json.dumps(step_function_output)\n",
        "                item['step_function_output'] = {'S': serialized_output}\n",
        "            except (TypeError, ValueError):\n",
        "                item['step_function_output'] = {'S': str(step_function_output)}\n",
        "        if lambda_output:\n",
        "            try:\n",
        "                serialized_lambda_output = json.dumps(lambda_output)\n",
        "                item['lambda_output'] = {'S': serialized_lambda_output}\n",
        "            except (TypeError, ValueError):\n",
        "                item['lambda_output'] = {'S': str(lambda_output)}\n",
        "\n",
        "        dynamodb.put_item(TableName=DYNAMODB_TABLE, Item=item)\n",
        "        print(f\"Logged step '{step}' for execution '{execution_id}' to DynamoDB.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error logging to DynamoDB: {str(e)}\")\n",
        "\n",
        "def create_dlq(dlq_name):\n",
        "    try:\n",
        "        response = sqs_client.create_queue(QueueName=dlq_name)\n",
        "        print(f\"Created DLQ: {response['QueueUrl']}\")\n",
        "        return response['QueueUrl']\n",
        "    except sqs_client.exceptions.QueueNameExists:\n",
        "        response = sqs_client.get_queue_url(QueueName=dlq_name)\n",
        "        print(f\"DLQ already exists: {response['QueueUrl']}\")\n",
        "        return response['QueueUrl']\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating DLQ: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def set_redrive_policy(primary_queue_url, dlq_url, max_receive_count=3):\n",
        "    try:\n",
        "        dlq_attributes = sqs_client.get_queue_attributes(\n",
        "            QueueUrl=dlq_url,\n",
        "            AttributeNames=['QueueArn']\n",
        "        )\n",
        "        dlq_arn = dlq_attributes['Attributes']['QueueArn']\n",
        "\n",
        "        redrive_policy = {\n",
        "            'maxReceiveCount': str(max_receive_count),\n",
        "            'deadLetterTargetArn': dlq_arn\n",
        "        }\n",
        "\n",
        "        sqs_client.set_queue_attributes(\n",
        "            QueueUrl=primary_queue_url,\n",
        "            Attributes={\n",
        "                'RedrivePolicy': json.dumps(redrive_policy)\n",
        "            }\n",
        "        )\n",
        "        print(f\"Redrive policy set with DLQ: {dlq_url} and maxReceiveCount: {max_receive_count}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting redrive policy: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def purge_sqs_queue(queue_url):\n",
        "    try:\n",
        "        response = sqs_client.purge_queue(QueueUrl=queue_url)\n",
        "        print(f\"Purged SQS queue: {queue_url}\")\n",
        "    except sqs_client.exceptions.QueueDoesNotExist:\n",
        "        print(f\"Queue {queue_url} does not exist.\")\n",
        "    except sqs_client.exceptions.PurgeQueueInProgress:\n",
        "        print(f\"Purge already in progress for queue {queue_url}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error purging SQS queue {queue_url}: {str(e)}\")\n",
        "\n",
        "def send_event_to_sqs(event, actual_source, predicted_source, retry_count=0):\n",
        "    try:\n",
        "        message_body = {\n",
        "            \"eventName\": event[\"eventName\"],\n",
        "            \"predicted_source\": predicted_source,\n",
        "            \"actual_source\": actual_source,\n",
        "            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "            \"retry_count\": retry_count\n",
        "        }\n",
        "        response = sqs_client.send_message(\n",
        "            QueueUrl=PRIMARY_SQS_QUEUE_URL,\n",
        "            MessageBody=json.dumps(message_body)\n",
        "        )\n",
        "        print(f\"Sent mismatched event '{event['eventName']}' to SQS. Message ID: {response['MessageId']}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'SQS Send',\n",
        "            200,\n",
        "            f\"Mismatched event '{event['eventName']}' sent to SQS\",\n",
        "            predicted_source,\n",
        "            event.get(\"score\"),\n",
        "            response\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending event to SQS: {str(e)}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'SQS Send',\n",
        "            500,\n",
        "            f\"Failed to send event '{event['eventName']}' to SQS: {str(e)}\",\n",
        "            predicted_source,\n",
        "            event.get(\"score\"),\n",
        "            None\n",
        "        )\n",
        "\n",
        "def process_sqs_queue():\n",
        "    try:\n",
        "        while True:\n",
        "            response = sqs_client.receive_message(\n",
        "                QueueUrl=PRIMARY_SQS_QUEUE_URL,\n",
        "                MaxNumberOfMessages=10,\n",
        "                WaitTimeSeconds=10\n",
        "            )\n",
        "\n",
        "            messages = response.get('Messages', [])\n",
        "            if not messages:\n",
        "                print(\"No more messages in SQS queue.\")\n",
        "                break\n",
        "\n",
        "            for message in messages:\n",
        "                receipt_handle = message['ReceiptHandle']\n",
        "                body = json.loads(message['Body'])\n",
        "                event_name = body['eventName']\n",
        "                retry_count = body.get('retry_count', 0)\n",
        "\n",
        "                predicted_source = EVENT_NAME_TO_SOURCE.get(event_name, \"Unknown\")\n",
        "                if predicted_source == \"Unknown\":\n",
        "                    print(f\"Failed to find source for event '{event_name}'.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Re-predicted source for event '{event_name}': {predicted_source}\")\n",
        "                invoke_step_function(predicted_source, event_name)\n",
        "\n",
        "                sqs_client.delete_message(\n",
        "                    QueueUrl=PRIMARY_SQS_QUEUE_URL,\n",
        "                    ReceiptHandle=receipt_handle\n",
        "                )\n",
        "                print(f\"Deleted SQS message for event '{event_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing SQS queue: {str(e)}\")\n",
        "\n",
        "def is_source_matching(actual_source, predicted_source):\n",
        "    \"\"\"\n",
        "    Determines if the predicted source matches the actual source.\n",
        "    Handles cases where the predicted source has a domain suffix.\n",
        "    \"\"\"\n",
        "    source_mapping = {\n",
        "        \"myapp.cloudshell\": \"cloudshell.amazonaws.com\",\n",
        "        \"myapp.ec2\": \"ec2.amazonaws.com\",\n",
        "        \"myapp.cloudtrail\": \"cloudtrail.amazonaws.com\"\n",
        "    }\n",
        "\n",
        "    mapped_actual_source = source_mapping.get(actual_source, actual_source)\n",
        "\n",
        "    core_actual = mapped_actual_source.split('.')[0]\n",
        "    core_predicted = predicted_source.split('.')[0]\n",
        "\n",
        "    return core_actual == core_predicted\n",
        "\n",
        "# Step 1: Invoking EventEmitterFunction\n",
        "def invoke_event_emitter(num_events=10):\n",
        "    print(\"Step 1: Invoking EventEmitterFunction...\")\n",
        "    try:\n",
        "        response = lambda_client.invoke(\n",
        "            FunctionName=EVENT_EMITTER_FUNCTION,\n",
        "            InvocationType='RequestResponse',\n",
        "            Payload=json.dumps({\"num_events\": num_events})\n",
        "        )\n",
        "        result = json.loads(response['Payload'].read())\n",
        "\n",
        "        print(f\"Response from EventEmitterFunction:\\n{json.dumps(result, indent=2)}\")\n",
        "\n",
        "        if result.get(\"statusCode\") == 200 and \"events\" in result:\n",
        "            return result[\"events\"]\n",
        "        else:\n",
        "            raise Exception(f\"Invalid response from EventEmitterFunction: {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking EventEmitterFunction: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Step 2: Send events to EventBridge\n",
        "def send_events_to_eventbridge(events):\n",
        "    print(f\"Step 2: Sending {len(events)} event(s) to EventBridge...\")\n",
        "    entries = []\n",
        "    for event in events:\n",
        "        entries.append({\n",
        "            \"EventBusName\": EVENT_BUS_NAME,\n",
        "            \"Source\": event[\"predicted_source\"],\n",
        "            \"DetailType\": \"AWS API Call via EventEmitterFunction\",\n",
        "            \"Detail\": json.dumps({\n",
        "                \"eventName\": event[\"eventName\"],\n",
        "                \"score\": event.get(\"score\")\n",
        "            })\n",
        "        })\n",
        "\n",
        "    try:\n",
        "        response = eventbridge_client.put_events(\n",
        "            Entries=entries\n",
        "        )\n",
        "        print(f\"Response from EventBridge:\\n{json.dumps(response, indent=2)}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'Step 2',\n",
        "            200,\n",
        "            f\"{len(events)} event(s) sent to EventBridge\",\n",
        "            None,\n",
        "            None,\n",
        "            response\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending events to EventBridge: {str(e)}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'Step 2',\n",
        "            500,\n",
        "            f\"Failed to send events to EventBridge: {str(e)}\",\n",
        "            None,\n",
        "            None,\n",
        "            None\n",
        "        )\n",
        "        raise\n",
        "\n",
        "# Step 3: Wait for EventBridge processing\n",
        "def wait_for_eventbridge_processing():\n",
        "    print(f\"Step 3: Waiting {WAIT_TIME} seconds for EventBridge processing...\")\n",
        "    time.sleep(WAIT_TIME)\n",
        "\n",
        "# Step 4: Invoking SendEventsToSageMaker for predictions\n",
        "def invoke_sagemaker_lambda(event_names):\n",
        "    print(f\"Step 4: Invoking SendEventsToSageMaker for {len(event_names)} event(s)...\")\n",
        "    try:\n",
        "        response = lambda_client.invoke(\n",
        "            FunctionName=SEND_EVENTS_TO_SAGEMAKER_FUNCTION,\n",
        "            InvocationType='RequestResponse',\n",
        "            Payload=json.dumps({\n",
        "                \"inputs\": event_names\n",
        "            })\n",
        "        )\n",
        "        result = json.loads(response['Payload'].read())\n",
        "        print(f\"Response from SendEventsToSageMaker:\\n{json.dumps(result, indent=2)}\")\n",
        "\n",
        "        # Update validation to handle batch predictions\n",
        "        if \"predictions\" not in result:\n",
        "            raise Exception(f\"Invalid response from SendEventsToSageMaker: {result}\")\n",
        "\n",
        "        # Log the SageMaker predictions\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'Step 4',\n",
        "            result.get(\"statusCode\", 200),\n",
        "            f\"Prediction successful for {len(result['predictions'])} event(s)\",\n",
        "            None,\n",
        "            None,\n",
        "            result\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking SendEventsToSageMaker Lambda: {str(e)}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'Step 4',\n",
        "            500,\n",
        "            f\"Failed to invoke SendEventsToSageMaker Lambda: {str(e)}\",\n",
        "            None,\n",
        "            None,\n",
        "            None\n",
        "        )\n",
        "        raise\n",
        "\n",
        "# Helper function to map myapp sources to AWS domains\n",
        "def map_to_aws_domain(source):\n",
        "    source_mapping = {\n",
        "        \"myapp.cloudshell\": \"cloudshell.amazonaws.com\",\n",
        "        \"myapp.ec2\": \"ec2.amazonaws.com\",\n",
        "        \"myapp.cloudtrail\": \"cloudtrail.amazonaws.com\"\n",
        "    }\n",
        "    return source_mapping.get(source, source)\n",
        "\n",
        "# Step 5: Start Step Function execution\n",
        "def invoke_step_function(predicted_source, event_name):\n",
        "    aws_domain_source = map_to_aws_domain(predicted_source)\n",
        "\n",
        "    input_payload = {\n",
        "        \"predicted_source\": aws_domain_source,\n",
        "        \"event_name\": event_name\n",
        "    }\n",
        "    print(f\"Step 5: Starting Step Function with input:\\n{json.dumps(input_payload, indent=2)}\")\n",
        "    try:\n",
        "        response = stepfunctions_client.start_execution(\n",
        "            stateMachineArn=STATE_MACHINE_ARN,\n",
        "            input=json.dumps(input_payload)\n",
        "        )\n",
        "        execution_arn = response['executionArn']\n",
        "        print(f\"Step Function started with Execution ARN: {execution_arn}\")\n",
        "\n",
        "        while True:\n",
        "            execution_status = stepfunctions_client.describe_execution(\n",
        "                executionArn=execution_arn\n",
        "            )\n",
        "            status = execution_status['status']\n",
        "            print(f\"Current Execution Status: {status}\")\n",
        "\n",
        "            if status in ['SUCCEEDED', 'FAILED', 'TIMED_OUT', 'ABORTED']:\n",
        "                break\n",
        "            time.sleep(WAIT_TIME)\n",
        "\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        if status == 'SUCCEEDED':\n",
        "            output = json.loads(execution_status['output'])\n",
        "            print(\"Execution succeeded with output:\")\n",
        "            print(json.dumps(output, indent=2))\n",
        "            log_to_dynamodb(\n",
        "                execution_id,\n",
        "                'Step 5',\n",
        "                200,\n",
        "                \"Step Function succeeded\",\n",
        "                aws_domain_source,\n",
        "                None,\n",
        "                None,\n",
        "                status,\n",
        "                output\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Execution failed with status: {status}\")\n",
        "            log_to_dynamodb(\n",
        "                execution_id,\n",
        "                'Step 5',\n",
        "                500,\n",
        "                f\"Step Function failed: {status}\",\n",
        "                aws_domain_source,\n",
        "                None,\n",
        "                None,\n",
        "                status,\n",
        "                None\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking Step Function: {str(e)}\")\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        log_to_dynamodb(\n",
        "            execution_id,\n",
        "            'Step 5',\n",
        "            500,\n",
        "            f\"Failed to start or monitor Step Function: {str(e)}\",\n",
        "            aws_domain_source,\n",
        "            None,\n",
        "            None,\n",
        "            None,\n",
        "            None\n",
        "        )\n",
        "        raise\n",
        "\n",
        "# Full workflow\n",
        "def test_full_workflow():\n",
        "    try:\n",
        "        # Step 1: Invoke EventEmitterFunction with num_events=10\n",
        "        num_events_to_generate = 10\n",
        "        events = invoke_event_emitter(num_events=num_events_to_generate)\n",
        "\n",
        "        # Step 2: Send all events to EventBridge\n",
        "        send_events_to_eventbridge(events)\n",
        "\n",
        "        # Step 3: Wait for EventBridge to process and route the events\n",
        "        wait_for_eventbridge_processing()\n",
        "\n",
        "        # Step 4: Get predictions from SendEventsToSageMaker\n",
        "        event_names = [event[\"eventName\"] for event in events]\n",
        "        prediction_response = invoke_sagemaker_lambda(event_names)\n",
        "\n",
        "        # Process each prediction\n",
        "        for prediction in prediction_response.get(\"predictions\", []):\n",
        "            event_name = prediction[\"event_name\"]\n",
        "            predicted_source = prediction.get(\"predicted_source\")\n",
        "            score = prediction.get(\"score\")\n",
        "\n",
        "            if not predicted_source:\n",
        "                print(f\"Predicted source for event '{event_name}' not found. Skipping further processing.\")\n",
        "                execution_id = str(uuid.uuid4())\n",
        "                log_to_dynamodb(\n",
        "                    execution_id,\n",
        "                    'Validation',\n",
        "                    400,\n",
        "                    f\"Predicted source for event '{event_name}' not found.\",\n",
        "                    predicted_source,\n",
        "                    score,\n",
        "                    None\n",
        "                )\n",
        "                continue  # Skip to the next event\n",
        "\n",
        "            # Determine the actual source based on the event name\n",
        "            actual_source = EVENT_NAME_TO_SOURCE.get(event_name)\n",
        "\n",
        "            if not actual_source:\n",
        "                print(f\"Actual source for event '{event_name}' not found. Skipping further processing.\")\n",
        "                execution_id = str(uuid.uuid4())\n",
        "                log_to_dynamodb(\n",
        "                    execution_id,\n",
        "                    'Validation',\n",
        "                    400,\n",
        "                    f\"Actual source for event '{event_name}' not found.\",\n",
        "                    predicted_source,\n",
        "                    score,\n",
        "                    None\n",
        "                )\n",
        "                continue  # Skip to the next event\n",
        "\n",
        "            print(f\"Actual source for event '{event_name}': {actual_source}\")\n",
        "            print(f\"Predicted source for event '{event_name}': {predicted_source}\")\n",
        "\n",
        "            # Compare predicted_source with actual_source\n",
        "            if is_source_matching(actual_source, predicted_source):\n",
        "                print(f\"Source validation passed for event '{event_name}'. Proceeding with Step Function.\")\n",
        "                # Step 5: Start Step Function with prediction details\n",
        "                invoke_step_function(predicted_source, event_name)\n",
        "            else:\n",
        "                print(f\"Source validation failed for event '{event_name}'. Sending to SQS for reprocessing.\")\n",
        "                # Send the event to SQS for later processing with retry_count incremented\n",
        "                send_event_to_sqs({\n",
        "                    \"eventName\": event_name,\n",
        "                    \"score\": score\n",
        "                }, actual_source, predicted_source, retry_count=1)\n",
        "\n",
        "        # After processing all events, process SQS queue\n",
        "        process_sqs_queue()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during workflow test: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Create DLQ\n",
        "        DLQ_URL = create_dlq(DLQ_NAME)\n",
        "\n",
        "        # Set redrive policy with DLQ\n",
        "        set_redrive_policy(PRIMARY_SQS_QUEUE_URL, DLQ_URL, max_receive_count=3)\n",
        "\n",
        "        # Purge the SQS queue before starting the workflow\n",
        "        purge_sqs_queue(PRIMARY_SQS_QUEUE_URL)\n",
        "\n",
        "        # Optionally, wait a few seconds to ensure purge is complete\n",
        "        time.sleep(5)\n",
        "\n",
        "        # Run the full workflow\n",
        "        test_full_workflow()\n",
        "    except Exception as e:\n",
        "        print(f\"Setup failed: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "velN0R9_qRYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}